"""
Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„ÙƒØ´Ù Ø§Ù„Ø§Ø­ØªÙŠØ§Ù„ Ø§Ù„Ù…Ø§Ù„ÙŠ
Advanced Machine Learning Engine for Fraud Detection
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, IsolationForest
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import joblib
import json
from datetime import datetime
import random


class AdvancedFraudDetectionEngine:
    """Ù…Ø­Ø±Ùƒ Ù…ØªÙ‚Ø¯Ù… Ù„ÙƒØ´Ù Ø§Ù„Ø§Ø­ØªÙŠØ§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ ML Ù…ØªØ¹Ø¯Ø¯Ø©"""
    
    def __init__(self):
        self.random_forest = None
        self.gradient_boosting = None
        self.isolation_forest = None
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.is_trained = False
        
        # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø´ÙƒÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ
        self._initialize_models()
    
    def _initialize_models(self):
        """ØªÙ‡ÙŠØ¦Ø© ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
        # ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ©
        training_data = self._generate_synthetic_training_data(5000)
        self._train_models(training_data)
    
    def _generate_synthetic_training_data(self, n_samples=5000):
        """ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ©"""
        np.random.seed(42)
        data = []
        
        for i in range(n_samples):
            # ØªÙˆÙ„ÙŠØ¯ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¹Ø§Ø¯ÙŠØ© (70%)
            if i < n_samples * 0.7:
                transaction = {
                    'amount': np.random.uniform(10, 5000),
                    'balance': np.random.uniform(5000, 100000),
                    'age': np.random.randint(25, 65),
                    'transaction_type': np.random.choice(['Ø´Ø±Ø§Ø¡', 'ØªØ­ÙˆÙŠÙ„_Ù…Ø­Ù„ÙŠ', 'Ø¯ÙØ¹_ÙÙˆØ§ØªÙŠØ±']),
                    'payment_method': np.random.choice(['Ø¨Ø·Ø§Ù‚Ø©_Ø§Ø¦ØªÙ…Ø§Ù†', 'Ø¨Ø·Ø§Ù‚Ø©_Ø®ØµÙ…', 'ØªØ­ÙˆÙŠÙ„_Ø¨Ù†ÙƒÙŠ']),
                    'hour': np.random.randint(8, 22),
                    'day_of_week': np.random.randint(0, 7),
                    'location_risk': np.random.uniform(0, 0.3),
                    'device_trust': np.random.uniform(0.7, 1.0),
                    'is_fraud': 0
                }
            # ØªÙˆÙ„ÙŠØ¯ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ø­ØªÙŠØ§Ù„ÙŠØ© (30%)
            else:
                transaction = {
                    'amount': np.random.uniform(5000, 100000),
                    'balance': np.random.uniform(100, 10000),
                    'age': np.random.randint(18, 75),
                    'transaction_type': np.random.choice(['ØªØ­ÙˆÙŠÙ„_Ø¯ÙˆÙ„ÙŠ', 'Ø³Ø­Ø¨_Ù†Ù‚Ø¯ÙŠ', 'Ø´Ø±Ø§Ø¡']),
                    'payment_method': np.random.choice(['Ù†Ù‚Ø¯', 'Ù…Ø­ÙØ¸Ø©_Ø±Ù‚Ù…ÙŠØ©']),
                    'hour': np.random.choice(list(range(0, 6)) + list(range(23, 24))),
                    'day_of_week': np.random.randint(0, 7),
                    'location_risk': np.random.uniform(0.6, 1.0),
                    'device_trust': np.random.uniform(0, 0.4),
                    'is_fraud': 1
                }
            
            data.append(transaction)
        
        return pd.DataFrame(data)
    
    def _prepare_features(self, df, fit=False):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ù„Ù†Ù…Ø§Ø°Ø¬"""
        # Ù†Ø³Ø® Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df_processed = df.copy()
        
        # Ø­Ø³Ø§Ø¨ Ù…ÙŠØ²Ø§Øª Ù…Ø´ØªÙ‚Ø©
        df_processed['amount_to_balance_ratio'] = df_processed['amount'] / (df_processed['balance'] + 1)
        df_processed['is_high_amount'] = (df_processed['amount'] > 10000).astype(int)
        df_processed['is_night_transaction'] = ((df_processed['hour'] < 6) | (df_processed['hour'] > 22)).astype(int)
        df_processed['is_weekend'] = (df_processed['day_of_week'] >= 5).astype(int)
        
        # ØªØ±Ù…ÙŠØ² Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©
        categorical_features = ['transaction_type', 'payment_method']
        
        for feature in categorical_features:
            if fit:
                self.label_encoders[feature] = LabelEncoder()
                df_processed[feature + '_encoded'] = self.label_encoders[feature].fit_transform(df_processed[feature])
            else:
                if feature in self.label_encoders:
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
                    df_processed[feature + '_encoded'] = df_processed[feature].apply(
                        lambda x: self.label_encoders[feature].transform([x])[0] 
                        if x in self.label_encoders[feature].classes_ 
                        else -1
                    )
                else:
                    df_processed[feature + '_encoded'] = 0
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        feature_columns = [
            'amount', 'balance', 'age', 'hour', 'day_of_week',
            'location_risk', 'device_trust', 'amount_to_balance_ratio',
            'is_high_amount', 'is_night_transaction', 'is_weekend',
            'transaction_type_encoded', 'payment_method_encoded'
        ]
        
        X = df_processed[feature_columns]
        
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if fit:
            X_scaled = self.scaler.fit_transform(X)
        else:
            X_scaled = self.scaler.transform(X)
        
        return X_scaled, feature_columns
    
    def _train_models(self, training_data):
        """ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        # ÙØµÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ù‡Ø¯Ù
        X, feature_columns = self._prepare_features(training_data, fit=True)
        y = training_data['is_fraud'].values
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # ØªØ¯Ø±ÙŠØ¨ Random Forest
        self.random_forest = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
        self.random_forest.fit(X_train, y_train)
        
        # ØªØ¯Ø±ÙŠØ¨ Gradient Boosting
        self.gradient_boosting = GradientBoostingClassifier(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            random_state=42
        )
        self.gradient_boosting.fit(X_train, y_train)
        
        # ØªØ¯Ø±ÙŠØ¨ Isolation Forest (Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø´Ø°ÙˆØ°)
        self.isolation_forest = IsolationForest(
            contamination=0.3,
            random_state=42,
            n_jobs=-1
        )
        self.isolation_forest.fit(X_train)
        
        self.is_trained = True
        
        # Ø­Ø³Ø§Ø¨ Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        rf_score = self.random_forest.score(X_test, y_test)
        gb_score = self.gradient_boosting.score(X_test, y_test)
        
        print(f"âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
        print(f"   Random Forest Accuracy: {rf_score:.4f}")
        print(f"   Gradient Boosting Accuracy: {gb_score:.4f}")
    
    def predict_fraud(self, transaction_data):
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø§Ø­ØªÙŠØ§Ù„ Ù„Ù…Ø¹Ø§Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©"""
        if not self.is_trained:
            raise Exception("Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØºÙŠØ± Ù…Ø¯Ø±Ø¨Ø© Ø¨Ø¹Ø¯")
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame
        df = pd.DataFrame([transaction_data])
        
        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª
        X, _ = self._prepare_features(df, fit=False)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Random Forest
        rf_proba = self.random_forest.predict_proba(X)[0][1]
        rf_prediction = self.random_forest.predict(X)[0]
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gradient Boosting
        gb_proba = self.gradient_boosting.predict_proba(X)[0][1]
        gb_prediction = self.gradient_boosting.predict(X)[0]
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Isolation Forest
        iso_prediction = self.isolation_forest.predict(X)[0]
        iso_score = self.isolation_forest.score_samples(X)[0]
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ensemble)
        ensemble_proba = (rf_proba * 0.4 + gb_proba * 0.4 + (1 if iso_prediction == -1 else 0) * 0.2)
        ensemble_prediction = 1 if ensemble_proba > 0.5 else 0
        
        # Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ø®Ø§Ø·Ø± (0-100)
        risk_score = min(100, int(ensemble_proba * 100))
        
        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±
        if risk_score < 30:
            risk_level = "Ù…Ù†Ø®ÙØ¶"
            risk_color = "green"
        elif risk_score < 70:
            risk_level = "Ù…ØªÙˆØ³Ø·"
            risk_color = "orange"
        else:
            risk_level = "Ø¹Ø§Ù„ÙŠ"
            risk_color = "red"
        
        # ØªØ­Ù„ÙŠÙ„ Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±
        risk_factors = self._analyze_risk_factors(transaction_data, X)
        
        return {
            'is_fraud': bool(ensemble_prediction),
            'fraud_probability': round(ensemble_proba * 100, 2),
            'risk_score': risk_score,
            'risk_level': risk_level,
            'risk_color': risk_color,
            'risk_factors': risk_factors,
            'model_predictions': {
                'random_forest': {
                    'prediction': bool(rf_prediction),
                    'probability': round(rf_proba * 100, 2)
                },
                'gradient_boosting': {
                    'prediction': bool(gb_prediction),
                    'probability': round(gb_proba * 100, 2)
                },
                'isolation_forest': {
                    'is_anomaly': bool(iso_prediction == -1),
                    'anomaly_score': round(float(iso_score), 4)
                }
            },
            'confidence': round((max(rf_proba, 1-rf_proba) + max(gb_proba, 1-gb_proba)) / 2 * 100, 2)
        }
    
    def _analyze_risk_factors(self, transaction_data, X):
        """ØªØ­Ù„ÙŠÙ„ Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±"""
        factors = []
        
        amount = transaction_data.get('amount', 0)
        balance = transaction_data.get('balance', 0)
        age = transaction_data.get('age', 0)
        hour = transaction_data.get('hour', 12)
        location_risk = transaction_data.get('location_risk', 0)
        device_trust = transaction_data.get('device_trust', 1)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¨Ù„Øº
        if balance > 0:
            ratio = amount / balance
            if ratio > 1.5:
                factors.append({
                    'factor': 'Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¨Ù„Øº Ø¥Ù„Ù‰ Ø§Ù„Ø±ØµÙŠØ¯',
                    'severity': 'Ø¹Ø§Ù„ÙŠ',
                    'description': f'Ø§Ù„Ù…Ø¨Ù„Øº ({amount:.2f}) ÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„Ø±ØµÙŠØ¯ ({balance:.2f}) Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ±'
                })
            elif ratio > 0.7:
                factors.append({
                    'factor': 'Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¨Ù„Øº Ø¥Ù„Ù‰ Ø§Ù„Ø±ØµÙŠØ¯',
                    'severity': 'Ù…ØªÙˆØ³Ø·',
                    'description': f'Ø§Ù„Ù…Ø¨Ù„Øº ({amount:.2f}) ÙƒØ¨ÙŠØ± Ù†Ø³Ø¨ÙŠØ§Ù‹ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø±ØµÙŠØ¯ ({balance:.2f})'
                })
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆÙ‚Øª
        if hour < 6 or hour > 22:
            factors.append({
                'factor': 'ØªÙˆÙ‚ÙŠØª Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø©',
                'severity': 'Ù…ØªÙˆØ³Ø·',
                'description': f'Ù…Ø¹Ø§Ù…Ù„Ø© ÙÙŠ ÙˆÙ‚Øª ØºÙŠØ± Ù…Ø¹ØªØ§Ø¯ (Ø§Ù„Ø³Ø§Ø¹Ø© {hour}:00)'
            })
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆÙ‚Ø¹
        if location_risk > 0.6:
            factors.append({
                'factor': 'Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠ',
                'severity': 'Ø¹Ø§Ù„ÙŠ',
                'description': 'Ù…ÙˆÙ‚Ø¹ Ø¬ØºØ±Ø§ÙÙŠ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ù…Ø®Ø§Ø·Ø±'
            })
        elif location_risk > 0.4:
            factors.append({
                'factor': 'Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠ',
                'severity': 'Ù…ØªÙˆØ³Ø·',
                'description': 'Ù…ÙˆÙ‚Ø¹ Ø¬ØºØ±Ø§ÙÙŠ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø®Ø§Ø·Ø±'
            })
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù‡Ø§Ø²
        if device_trust < 0.4:
            factors.append({
                'factor': 'Ø«Ù‚Ø© Ø§Ù„Ø¬Ù‡Ø§Ø²',
                'severity': 'Ø¹Ø§Ù„ÙŠ',
                'description': 'Ø¬Ù‡Ø§Ø² ØºÙŠØ± Ù…ÙˆØ«ÙˆÙ‚ Ø£Ùˆ Ù…Ø´Ø¨ÙˆÙ‡'
            })
        elif device_trust < 0.6:
            factors.append({
                'factor': 'Ø«Ù‚Ø© Ø§Ù„Ø¬Ù‡Ø§Ø²',
                'severity': 'Ù…ØªÙˆØ³Ø·',
                'description': 'Ø¬Ù‡Ø§Ø² Ø°Ùˆ Ø«Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø©'
            })
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„ÙƒØ¨ÙŠØ±
        if amount > 50000:
            factors.append({
                'factor': 'Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø©',
                'severity': 'Ù…ØªÙˆØ³Ø·',
                'description': f'Ù…Ø¨Ù„Øº ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹ ({amount:.2f} Ø±ÙŠØ§Ù„)'
            })
        
        return factors
    
    def get_feature_importance(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª"""
        if not self.is_trained or self.random_forest is None:
            return {}
        
        feature_names = [
            'Ø§Ù„Ù…Ø¨Ù„Øº', 'Ø§Ù„Ø±ØµÙŠØ¯', 'Ø§Ù„Ø¹Ù…Ø±', 'Ø§Ù„Ø³Ø§Ø¹Ø©', 'ÙŠÙˆÙ… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹',
            'Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…ÙˆÙ‚Ø¹', 'Ø«Ù‚Ø© Ø§Ù„Ø¬Ù‡Ø§Ø²', 'Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¨Ù„Øº/Ø§Ù„Ø±ØµÙŠØ¯',
            'Ù…Ø¨Ù„Øº ÙƒØ¨ÙŠØ±', 'Ù…Ø¹Ø§Ù…Ù„Ø© Ù„ÙŠÙ„ÙŠØ©', 'Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹',
            'Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø©', 'Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¯ÙØ¹'
        ]
        
        importances = self.random_forest.feature_importances_
        
        feature_importance = {}
        for name, importance in zip(feature_names, importances):
            feature_importance[name] = round(float(importance), 4)
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©
        sorted_features = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True))
        
        return sorted_features
    
    def save_models(self, path='models/'):
        """Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©"""
        import os
        os.makedirs(path, exist_ok=True)
        
        joblib.dump(self.random_forest, f'{path}random_forest.pkl')
        joblib.dump(self.gradient_boosting, f'{path}gradient_boosting.pkl')
        joblib.dump(self.isolation_forest, f'{path}isolation_forest.pkl')
        joblib.dump(self.scaler, f'{path}scaler.pkl')
        joblib.dump(self.label_encoders, f'{path}label_encoders.pkl')
        
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙÙŠ {path}")
    
    def load_models(self, path='models/'):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©"""
        import os
        
        if not os.path.exists(path):
            print("âš ï¸ Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø³ÙŠØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ø¬Ø¯ÙŠØ¯")
            return False
        
        try:
            self.random_forest = joblib.load(f'{path}random_forest.pkl')
            self.gradient_boosting = joblib.load(f'{path}gradient_boosting.pkl')
            self.isolation_forest = joblib.load(f'{path}isolation_forest.pkl')
            self.scaler = joblib.load(f'{path}scaler.pkl')
            self.label_encoders = joblib.load(f'{path}label_encoders.pkl')
            self.is_trained = True
            
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ù† {path}")
            return True
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}")
            return False


# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø­Ø±Ùƒ
if __name__ == "__main__":
    print("ğŸš€ ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø§Ø­ØªÙŠØ§Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
    engine = AdvancedFraudDetectionEngine()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù…Ù„Ø© Ø¹Ø§Ø¯ÙŠØ©
    normal_transaction = {
        'amount': 500,
        'balance': 25000,
        'age': 35,
        'transaction_type': 'Ø´Ø±Ø§Ø¡',
        'payment_method': 'Ø¨Ø·Ø§Ù‚Ø©_Ø§Ø¦ØªÙ…Ø§Ù†',
        'hour': 14,
        'day_of_week': 2,
        'location_risk': 0.1,
        'device_trust': 0.9
    }
    
    print("\nğŸ“Š Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù…Ù„Ø© Ø¹Ø§Ø¯ÙŠØ©:")
    result = engine.predict_fraud(normal_transaction)
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù…Ù„Ø© Ù…Ø´Ø¨ÙˆÙ‡Ø©
    suspicious_transaction = {
        'amount': 75000,
        'balance': 5000,
        'age': 22,
        'transaction_type': 'ØªØ­ÙˆÙŠÙ„_Ø¯ÙˆÙ„ÙŠ',
        'payment_method': 'Ù†Ù‚Ø¯',
        'hour': 3,
        'day_of_week': 6,
        'location_risk': 0.9,
        'device_trust': 0.2
    }
    
    print("\nğŸš¨ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù…Ù„Ø© Ù…Ø´Ø¨ÙˆÙ‡Ø©:")
    result = engine.predict_fraud(suspicious_transaction)
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    # Ø¹Ø±Ø¶ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
    print("\nğŸ“ˆ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª:")
    feature_importance = engine.get_feature_importance()
    for feature, importance in list(feature_importance.items())[:5]:
        print(f"   {feature}: {importance:.4f}")
